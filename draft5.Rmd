---
title: "draft2"
author: "Evgenia Charalambous"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries and datasets

```{r}
library(readr)
library(ggplot2) 
library(outbreaks)
library(tidyverse)
ebola<-read_csv("ebola.csv")
malaria<-read_csv("malaria.csv")
```

Perform some analysis on the ebola dataset first

```{r}
sum(ebola$DateOnset == ebola$DateOnsetInferred, na.rm = TRUE)
sum(is.na(ebola$DateOnset))
sum(is.na(ebola$DateOnsetInferred))
nrow(ebola) - sum(is.na(ebola$DateOnset))
class(ebola$DateOnsetInferred)
```

Now create plots for the ebola dataset, including a histogram of the dates where 
new cases were recorded and a cumulative plot as well.

```{r}
newdat<- ebola[order(ebola$DateOnsetInferred, decreasing = FALSE), ]
total_days_2 <- as.integer(max(newdat$DateOnsetInferred, na.rm = TRUE) - min(newdat$DateOnsetInferred, na.rm = TRUE)) + 1
cum_cases<- cumsum(table(newdat$DateOnsetInferred))
cases<-table(newdat$DateOnsetInferred)
ggplot(data.frame(date = as.Date(names(cases)), cases = cases), aes(x = date, y = cases)) +
  geom_line(color = "red") +
  labs(title = "Count of Infections",
       x = "Time",
       y = "Count")

ggplot(data.frame(date = as.Date(names(cum_cases)), cum_cases = cum_cases), aes(x = date, y = cum_cases)) +
  geom_step(color = "steelblue", linewidth = 1) +
  labs(title = "Cumulative Plot of Cases for Ebola",
       x = "Days",
       y = "Cumulative Cases")


```

Plots per week


```{r}
# Calculate the start date
start_date <- min(newdat$DateOnsetInferred, na.rm = TRUE)

# Add a new column that is the number of weeks since the start date
newdat$Week <- as.numeric(difftime(newdat$DateOnsetInferred, start_date, units = "weeks"))

# Group by week, and then summarise to calculate the count of cases and cumulative cases in each week
library(dplyr)
# Group by week, and then summarise to calculate the count of cases in each week
week_dat <- newdat %>%
  group_by(Week = floor(Week)) %>%
  summarise(cases = n())

# Calculate the cumulative cases
week_dat$cum_cases <- cumsum(week_dat$cases)

# Now use ggplot to plot the cases and cumulative cases against week
ggplot(week_dat, aes(x = Week, y = cases)) +
  geom_line(color = "red") +
  labs(title = "Count of Infections",
       x = "Weeks",
       y = "Count")

ggplot(week_dat, aes(x = Week, y = cum_cases)) +
  geom_step(color = "steelblue", linewidth = 1) +
  labs(title = "Cumulative Plot of Cases for Ebola",
       x = "Weeks",
       y = "Cumulative Cases")

ggplot(week_dat, aes(x = Week, y = cases)) +
  geom_col(fill = "red") +
  labs(title = "Bar Plot of Cases for Ebola",
       x = "Number of Weeks",
       y = "Count")
```

Do the same for Ebola in Kikwit using the outbreaks library.


```{r}
library(outbreaks)
total_days <- as.integer(max(ebola_kikwit_1995$date) - min(ebola_kikwit_1995$date)) + 1
cumulative_cases <- cumsum((ebola_kikwit_1995$onset))
ggplot(data.frame(total_days = 1:total_days, cumulative_cases), aes(x = total_days, y = cumulative_cases)) +
  geom_step(color = "steelblue", linewidth = 1) +
  labs(title = "Cumulative Plot of Cases for Ebola in Kikwit",
       x = "Total Days",
       y = "Cumulative Cases")

ggplot(ebola_kikwit_1995, aes(x = 1:total_days, y = onset)) +
  geom_line(color = "red") +
  labs(title = "Line Plot of Onset",
       x = "Number of Days",
       y = "Count")

```
Now plot for the weeks:

```{r}
# Add a new column that is the number of weeks since the start date
ebola_kikwit_1995$Week <- as.numeric(difftime(ebola_kikwit_1995$date, min(ebola_kikwit_1995$date), units = "weeks"))

# Round off to the nearest whole number to get complete weeks
ebola_kikwit_1995$Week <- floor(ebola_kikwit_1995$Week)

# Group by week, and then summarise to calculate the count of cases in each week
library(dplyr)
week_dat_2 <- ebola_kikwit_1995 %>%
  group_by(Week) %>%
  summarise(onset = sum(onset))

# Calculate the cumulative cases
week_dat_2$cumulative_cases <- cumsum(week_dat_2$onset)

# Now use ggplot to plot the cases and cumulative cases against week
library(ggplot2)
ggplot(week_dat_2, aes(x = Week, y = onset)) +
  geom_line(color = "red") +
  labs(title = "Line Plot of Cases for Ebola in Kikwit",
       x = "Number of Weeks",
       y = "Count")

ggplot(week_dat_2, aes(x = Week, y = cumulative_cases)) +
  geom_step(color = "steelblue", linewidth = 1) +
  labs(title = "Cumulative Plot of Cases for Ebola in Kikwit",
       x = "Total Weeks",
       y = "Cumulative Cases")
ggplot(week_dat_2, aes(x = Week, y = onset)) +
  geom_col(fill = "red") +
  labs(title = "Bar Plot of Cases for Ebola in Kikwit",
       x = "Number of Weeks",
       y = "Count")

```


And also the same for the Zika virus

```{r}
zika_days<-as.integer(max(zika_girardot_2015$date) - min(zika_girardot_2015$date))+1
library(tidyverse)

all_dates <- seq(min(zika_girardot_2015$date), max(zika_girardot_2015$date), by = "day")

# Convert the dates in the original data frame to Date objects
zika_girardot_2015$date <- as.Date(zika_girardot_2015$date)

zika_girardot_filled <- zika_girardot_2015 %>%
  complete(date = all_dates) %>%
  mutate(cases = replace_na(cases, 0))
zika_girardot_filled<- as.data.frame(zika_girardot_filled)

ggplot(zika_girardot_filled, aes(x = 1:zika_days, y = cases)) +
  geom_line(color = "red") +
  labs(title = "Plot of Dates and Cases",
       x = "Dates",
       y = "Cases")
## Cumulative plot now
cum_cases_2 <- cumsum((zika_girardot_filled$cases))
ggplot(data.frame(total_days = 1:zika_days, cum_cases_2), aes(x = total_days, y = cum_cases_2)) +
  geom_step(color = "steelblue", linewidth = 1) +
  labs(title = "Cumulative Plot of Cases for Zika virus",
       x = "Total Days",
       y = "Cumulative Cases")
```

Do the same for weeks:

```{r}
# Convert date to Date class, if it's not already
zika_girardot_2015$date <- as.Date(zika_girardot_2015$date)

# Calculate the start date
start_date <- min(zika_girardot_2015$date)

# Add a new column that is the number of weeks since the start date
zika_girardot_2015$Week <- floor(as.numeric(difftime(zika_girardot_2015$date, start_date, units = "weeks")))

# Summarise the data by week
week_dat_3 <- zika_girardot_2015 %>%
  group_by(Week) %>%
  summarise(cases = sum(cases))

# Calculate the cumulative cases
week_dat_3$cum_cases <- cumsum(week_dat_3$cases)

# Plot of Dates and Cases
ggplot(week_dat_3, aes(x = Week, y = cases)) +
  geom_line(color = "red") +
  labs(title = "Plot of Weeks and Cases for Zika Virus",
       x = "Weeks",
       y = "Cases")

# Cumulative plot
ggplot(week_dat_3, aes(x = Week, y = cum_cases)) +
  geom_step(color = "steelblue", linewidth = 1) +
  labs(title = "Cumulative Plot of Cases for Zika virus",
       x = "Total Weeks",
       y = "Cumulative Cases")

ggplot(week_dat_3, aes(x = Week, y = cases)) +
  geom_col(fill = "red") +
  labs(title = "Plot of Weeks and Cases for Zika Virus",
       x = "Weeks",
       y = "Cases")
```

We can see that none of the plots show any periodicity. The first dataset of Ebola
might have an increasing trend however we will just use a constant exogenous term
$\mu$ for now.

We have 1936 counts for the Zika dataset. We generate using a uniform distribution
1936 timestamps to make it a continuous time.

```{r}
library(dplyr)
library(lubridate)
library(purrr)
set.seed(50)
df2 <- zika_girardot_2015 %>%
  mutate(date2 = as.POSIXct(date)) %>%
  mutate(case_hour = lapply(cases, function(x) as.list(as.integer(runif(x, 0, 24))))) %>%
  mutate(case_epoch = map2(date2, case_hour, function(d, h) d + hours(h)))

library(tidyr)
df2<-unnest(df2, case_epoch)
df2<- df2[order(df2$case_epoch),]
```

```{r}
library(epihawkes)
set.seed(5212)

#time <- as.numeric(zika_girardot_filled$date)
#inter_event_times <- diff(time)
#time_intervals <- diff(zika_girardot_filled$cases)
#event_times <- cumsum(time_intervals) / sum(time_intervals) * T_max
#new_times<-sort(new_times,decreasing=FALSE)
min_time <- min(df2$case_epoch)
df2$case_epoch <- df2$case_epoch - min_time
new_times <- c(as.integer(df2$case_epoch))/86400 # turn seconds to days
mu_term<- "constant"
mu_fn <- mu_constant
mu_diff_fn <- mu_diff_constant
mu_int_fn <- mu_int_constant
# Prints log level
print_level <- 1
params <- list(alpha = runif(1, 0, 1),
                   delta = runif(1, 0, 1),
                   A = runif(1, 0, 1))
print(params)
  
out <- optim(par = params, fn = neg_log_likelihood, gr = ray_derivatives,
                method = "L-BFGS-B",
                events = new_times, 
                kernel = ray_kernel, 
                mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                mu_int_fn = mu_int_fn,
                print_level = print_level)
print(sprintf("neg LL: %f", out$value))
print(paste(c("Optimal parameters:", out$par)))
```


Optimal parameters: alpha= 269.520401432356, delta = 291.15960765865, A = 10.6285642022424

```{r}
plot_decay_kernel(ray_kernel, parameters = as.list(out$par), T_max = 13)
```

$\mu$ is found to be $\approx$ 10.6. 

```{r}
library(ggplot2)
ts = 1:max(new_times)
ys = mu_fn(ts, parameters = as.list(out$par))
df <- data.frame(ts, ys)
p <- ggplot(df) + geom_line(aes(ts, ys)) + 
  ylab(expression(mu)) + xlab('t')
print(p)
```

Simulate data using the parameters

```{r}
library(ggplot2)
library(foreach)
library(doParallel)

N_runs <- 100
T_max = max(new_times)
set.seed(5)

# Register the parallel backend
no_cores <- detectCores()
registerDoParallel(cores=no_cores)

# Running the simulation in parallel
list_events <- foreach(i = 1:N_runs, .packages = "epihawkes") %dopar% {
  events <- hawkes_simulation(events = c(0), kernel = ray_kernel, 
                              T_max = max(new_times),
                              parameters = as.list(out$par), mu_fn = mu_fn,
                              print_level = print_level)
  events
}

# Creating a data frame for new_times
df_new_times <- data.frame(t = new_times, N = seq(1, length(new_times)), type = "Real Data")

# Initialize a list to hold all simulated event data frames
list_df_events <- list()

for(i in 1:N_runs){
  
  events <- list_events[[i]]
  
  # Creating a data frame for events
  df_events <- data.frame(t = events, N = seq(1, length(events)), type = paste("Simulated Data ", i))
  
  # Store each data frame in the list
  list_df_events[[i]] <- df_events
}

## CUMULATIVE PLOT

plot <- ggplot() +
  theme_bw() +
  labs(title = "Comparison of Simulated and Real Data",
       x = "Time (weeks)",
       y = "Count") +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines with alpha for transparency
for(i in 1:N_runs){
  plot <- plot + geom_line(data = list_df_events[[i]], aes(x = t, y = N), color = "black", alpha = 0.2)
}

# Add the real data line
plot <- plot + geom_line(data = df_new_times, aes(x = t, y = N), color = "red",alpha = 0.9)

# Display the cumulative plot
print(plot)

## NON cumulative plot

# Initialize an empty list to hold the data frames for each simulation
list_df_non_cum <- list()

# Loop over the list of simulations
for(i in 1:N_runs){
  # Convert simulation events from seconds to dates
  non_cum <- as.POSIXct(list_events[[i]] * 604800, origin = "2015-10-19")
  
  # Convert the filtered events to weeks from the origin
  non_cum <- floor(as.numeric(difftime(non_cum, "2015-10-19", units = "weeks")))

  # Create a data frame for the non-cumulative counts for this simulation
  non_cum_df <- data.frame(
    Week = as.numeric(names(table(non_cum))), 
    Simulated_Count = as.vector(table(non_cum)),
    True_count = week_dat_3$cases
  )
  
  # Add the data frame to the list
  list_df_non_cum[[i]] <- non_cum_df
}

# Plot setup
plot_non_cum <- ggplot() +
  theme_bw() +
  labs(title = "Non-Cumulative Counts of Simulated Events and True Observations",
       x = "Week",
       y = "Count") +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines with alpha for transparency
for(i in 1:N_runs){
  plot_non_cum <- plot_non_cum + geom_line(data = list_df_non_cum[[i]], aes(x = Week, y = Simulated_Count), color = "black", alpha = 0.2)
}

# Add the real data line
plot_non_cum <- plot_non_cum + geom_line(data = non_cum_df, aes(x = Week, y = True_count), color = "red",alpha = 0.9)

# Display the plot
print(plot_non_cum)
```

The intensity for a portion of the simulations

```{R}
out$par["delay"] = 0
data <- compute_intensity_function(events = events, kernel = ray_kernel, 
        T_max = max(new_times), parameters = as.list(out$par), mu_fn = mu_fn, 
        N = 5000)
mu_ts <- mu_fn(events, parameters =  as.list(out$par))
event_intensities <- mu_ts + conditional_intensity_list(times = events +1e-10, events = events, kernel = ray_kernel, parameters = as.list(out$par))
data_events <- data.frame(t = events, event_intensities = event_intensities)

library(RColorBrewer)


# Find the maximum and minimum intensity
max_intensity <- max(data$intensity)
min_intensity <- min(data$intensity)

# Find the times associated with the maximum and minimum intensity
max_time <- data$t[which.max(data$intensity)]
min_time <- data$t[which.min(data$intensity)]

# Get a sequence of breaks for the x-axis
x_breaks <- seq(floor(min(data$t)), ceiling(max(data$t)), 1)

# Add the min/max times to the original breaks
x_breaks_new <- round(sort(unique(c(x_breaks, min_time, max_time))))

# Use similar logic for the y-axis
y_breaks <- seq(floor(min(data$intensity)), ceiling(max(data$intensity)), 60)
#y_breaks_new <- round(sort(unique(c(y_breaks, min_intensity, max_intensity))))

# Create the plot
p3 <- ggplot(data, aes(t, intensity)) + 
  geom_line(aes(color = "intensity")) +
  geom_point(data = data_events, aes(t, event_intensities)) +
  scale_color_brewer(palette = "Set1") +
  labs(x = "Time (weeks)", y = expression(lambda(t)), color = "Type", 
       title = "Intensity plot") +
  theme_minimal() +
  # Add vertical and horizontal lines at the maximum and minimum points
  geom_vline(xintercept = max_time, linetype = "dashed", color = "red", size = 0.5) +
  geom_hline(yintercept = max_intensity, linetype = "dashed", color = "red", size = 0.5) +
  geom_vline(xintercept = min_time, linetype = "dashed", color = "blue", size = 0.5) +
  geom_hline(yintercept = min_intensity, linetype = "dashed", color = "blue", size = 0.5) +
  # Add breaks and labels at these points on the x and y axes 
  scale_x_continuous(breaks = x_breaks_new) +
  scale_y_continuous(breaks = y_breaks)

# Print the plot
print(p3)
```

We now plot the intensities of all simulations along with the true intensity

```{r}
# Calculate intensities for all simulations and real data
list_intensities <- list()
for(i in 1:N_runs){
  events <- list_events[[i]]
  out$par["delay"] = 0
  data <- compute_intensity_function(events = events, kernel = ray_kernel, 
        T_max = max(new_times), parameters = as.list(out$par), mu_fn = mu_fn, 
        N = 5000)
  mu_ts <- mu_fn(events, parameters =  as.list(out$par))
  event_intensities <- mu_ts + conditional_intensity_list(times = events +1e-10, events = events, kernel = ray_kernel, parameters = as.list(out$par))
  data_events <- data.frame(t = events, intensity = event_intensities, type = paste("Simulated Data ", i))
  list_intensities[[i]] <- data_events
}

# Calculate intensities for the real data
out$par["delay"] = 0
data <- compute_intensity_function(events = new_times, kernel = ray_kernel, 
        T_max = max(new_times), parameters = as.list(out$par), mu_fn = mu_fn, 
        N = 5000)
mu_ts <- mu_fn(new_times, parameters =  as.list(out$par))
event_intensities <- mu_ts + conditional_intensity_list(times = new_times +1e-10, events = new_times, kernel = ray_kernel, parameters = as.list(out$par))
df_new_times <- data.frame(t = new_times, intensity = event_intensities, type = "Real Data")


# plot the intensities
plot <- ggplot() +
  theme_bw() +
  labs(title = "Comparison of Simulated and Real Intensities",
       x = "Time (weeks)",
       y = expression(lambda(t))) +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines with alpha for transparency
for(i in 1:N_runs){
  plot <- plot + geom_line(data = list_intensities[[i]], aes(x = t, y = intensity), color = "black", alpha = 0.2)
}

# Add the real data line
plot <- plot + geom_line(data = df_new_times, aes(x = t, y = intensity), color = "red", alpha = 0.9)

# Display the plot
print(plot)
```


we now find parameters for simulated data to check the validity of our model.


```{r}
set.seed(187)
mu_term<- "constant"
mu_fn <- mu_constant
mu_diff_fn <- mu_diff_constant
mu_int_fn <- mu_int_constant
# Prints log level
print_level <- 1
params1 <- list(alpha = runif(1, 0, 1),
                   delta = runif(1, 0, 1),
                   A = runif(1, 0, 1))
# Create a new objective function that works with the transformed parameters
my_neg_log_likelihood <- function(log_params, ...) {
  # Transform the parameters back to their original scale
  params <- exp(log_params)
  
  print("Parameters:")
  print(params)
  
  # Compute the objective function value
  val <- neg_log_likelihood(params, ...)
  
  print("Function value:")
  print(val)
  
  return(val)
}

# Initial parameters on the log scale
log_params1 <- as.list(log(unlist(params1)))

transformed_gradients <- function(log_params, ...) {
  # Transform the parameters back to their original scale
  params <- exp(log_params)
  
  # Compute the original gradients
  orig_grads <- ray_derivatives(params, ...)
  
  # Adjust for the transformation
  trans_grads <- orig_grads * params  # because the derivative of exp is itself
  
  return(trans_grads)
}

library(doParallel)
library(foreach)

# Register the parallel backend
no_cores <- detectCores()
registerDoParallel(cores=no_cores)

# Define your function to optimize
optimize_func <- function(i){
  out <- optim(par = log_params1, fn = my_neg_log_likelihood, gr = transformed_gradients,
                     method = "BFGS",events = list_events[[i]], 
                     kernel = ray_kernel, 
                     mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                     mu_int_fn = mu_int_fn,
                     print_level = print_level)
  # Transform the parameters back to their original scale before storing them
  out$par <- exp(out$par)
  return(out)
}

# Running the optimization in parallel
out1 <- foreach(i = 1:N_runs, .export = c("log_params1", "my_neg_log_likelihood", "transformed_gradients", "neg_log_likelihood", "ray_derivatives",
                                           "ray_kernel", "mu_fn", "mu_diff_fn", "mu_int_fn", "print_level", "list_events"), 
                .packages = "stats") %dopar% {
  optimize_func(i)
}

# Stop the parallel backend
stopImplicitCluster()


```
Create density plots to compare the true parameters with the parameters deemed optimal from our simulations.

```{r}

new_pars <- list()
for(i in 1:N_runs){
  new_pars[[i]]<- out1[[i]]$par
  new_pars[[i]]$delay <- 0
}
estimated_pars <- do.call("rbind", new_pars)  # Bind all estimated parameters into a matrix
estimated_pars <- as.data.frame(estimated_pars)
library(ggplot2)
library(gridExtra)
# Create an empty list to store the plots
plot_list <- list()

#Create density plots
for(i in 1:length(out$par)) {
  # Create a dataframe for plotting
  plot_df <- data.frame(Estimated_Value = unlist(estimated_pars[, i]))
  
  # Generate a density plot for each parameter
  p <- ggplot(plot_df, aes(x = Estimated_Value)) +
    geom_density(fill = "skyblue", alpha = 0.7) +
    geom_vline(aes(xintercept = out$par[[i]]), color = "red", linetype = "dashed") +
    labs(title = paste("Parameter:", names(out$par)[i]),
         x = "Estimated Value",
         y = "Density") +
    theme_minimal()  # A clean theme
  
  # Store the plot in the list
  plot_list[[i]] <- p
}

# Arrange the plots in a grid
grid<-do.call(grid.arrange, c(plot_list, ncol = length(out$par)))

pdf("myplot.pdf", width = 15, height = 8.5) 

# Clear the grid graphical device
grid::grid.newpage()

# Draw the plot on the device
grid::grid.draw(grid)

# Close the device
dev.off()

```

Create boxplots


```{r}

# Create an empty list to store the boxplots
boxplot_list <- list()

# Loop over the parameters
for(i in 1:length(out$par)) {
  # Create a dataframe for plotting
  boxplot_df <- data.frame(Estimated_Value = unlist(estimated_pars[, i]))
  
  # Generate a boxplot for each parameter
  b <- ggplot(boxplot_df, aes(x = "", y = Estimated_Value)) +
    geom_boxplot(fill = "skyblue", alpha = 0.7) +
    geom_hline(aes(yintercept = out$par[[i]]), color = "red", linetype = "dashed") +
    labs(title = paste("Parameter:", names(out$par)[i]),
         x = "",
         y = "Estimated Value") +
    theme_minimal()  # A clean theme
  
  # Store the boxplot in the list
  boxplot_list[[i]] <- b
}

# Arrange the boxplots in a grid
grid_box<-do.call(grid.arrange, c(boxplot_list, ncol = length(out$par)))

pdf("boxplot.pdf", width = 15, height = 8.5) 

# Clear the grid graphical device
grid::grid.newpage()

# Draw the plot on the device
grid::grid.draw(grid_box)

# Close the device
dev.off()

```

Find $R_c$ for simulated events

```{r}
for(i in 1:N_runs){
  estimated_pars$Rc[i] <- unlist(estimated_pars$alpha)[i]/unlist(estimated_pars$delta)[i]
}

real_Rc <- out$par[1]/out$par[2]


# Create a dataframe for the Rc values
rc_df <- data.frame(Estimated_Rc = estimated_pars$Rc)

# Plot the density
pnew <- ggplot(rc_df, aes(x = Estimated_Rc)) +
    geom_density(fill = "skyblue", alpha = 0.5) +
    geom_vline(aes(xintercept = real_Rc), color = "red", linetype = "dashed") +
    labs(title = "Comparison of Real and Estimated Rc Values",
         x = "Estimated Rc Value",
         y = "Density") +
    theme_minimal()

print(pnew)

# Boxplot
boxplot(estimated_pars$Rc, main="Estimated Rc Values", ylab="Rc", border="blue", 
        col="lightgray", notch=TRUE, varwidth=TRUE)
abline(h = real_Rc, col="red", lty=2)

```

Use goodness of fit test to see whether our model is good.
```{r}
params<-c(mu = as.numeric(out$par[3]), alpha = as.numeric(out$par[1]), beta = as.numeric(out$par[2]))
show_hawkes_GOF(list(times = new_times,params = params))
new_times1 <- list_events[[1]] + 0.01
cumulative_intensities <- sapply(new_times1, function(t) {
  integral_intensity(events = new_times1[new_times1 <= t], int_kernel = int_ray, 
                     parameters = as.list(out$par), mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                     mu_int_fn = mu_int_fn)
})

ggplot(data.frame(x = 1:length(new_times1) , y=cumulative_intensities), aes(x = x, y = y)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  xlab("i") + 
  ylab(expression(Lambda(t[i]))) + 
  ggtitle("Cumulative Intensity vs Event Index") + 
  theme_minimal()
```


Moving on to using Ebola

```{r}
set.seed(52143)
df3 <- ebola_kikwit_1995 %>%
  filter(onset > 0) %>%
  mutate(date2 = as.POSIXct(date)) %>%
  mutate(case_hour = lapply(onset, function(x) as.list(as.integer(runif(x, 0, 24))))) %>%
  mutate(case_epoch = map2(date2, case_hour, function(d, h) d + hours(h)))

library(tidyr)
df3<-unnest(df3, case_epoch)
df3<- df3[order(df3$case_epoch),]

min_time <- min(df3$case_epoch)
df3$case_epoch <- df3$case_epoch - min_time
#True counts (days)
new_times_ebola <- c(as.integer(df3$case_epoch))/86400 # turn seconds to days
mu_term<- "constant"
mu_fn <- mu_constant
mu_diff_fn <- mu_diff_constant
mu_int_fn <- mu_int_constant
# Prints log level
print_level <- 1

params <- list(alpha = runif(1, 0, 1),
               delta = runif(1, 0, 1),
               A = runif(1,0,1),
               delay = runif(1,0,1))

params2 <- list(alpha = runif(1, 0, 1),
               delta = runif(1, 0, 1),
               A = runif(1,0,1),
               delay = runif(1,0,1))
set.seed(983)
params3 <- list(alpha = runif(1, 0, 2),
               delta = runif(1, 0, 2),
               A = runif(1,0,2),
               delay = runif(1,0,2))

out_ebola <- optim(par = params, fn = neg_log_likelihood, gr = ray_derivatives,
             method = "L-BFGS-B",
             events = new_times_ebola, 
             kernel = ray_kernel, 
             mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
             mu_int_fn = mu_int_fn,
             print_level = print_level)
print(sprintf("neg LL: %f", out_ebola$value))
print(paste(c("Optimal parameters:", out_ebola$par)))

```

First optim try with parameters $alpha
[1] 0.7052312

$delta
[1] 0.6956432

$A
[1] 0.9414585

$delay
[1] 0.2981311:

[1] "neg LL: -73.918937"
[1] "Optimal parameters:" "0.297573780447155"   "0.310415676934046"   "0.0695222134176735" 
[5] "-0.0452665814247681"


Second optim try with parameters

$alpha
[1] 0.07696313

$delta
[1] 0.3326702

$A
[1] 0.2858059

$delay
[1] 0.5975568:


[1] "neg LL: -73.918937"
[1] "Optimal parameters:" "0.297574683070198"   "0.310416918884019"   "0.0695245144373156" 
[5] "-0.0452596566837732"

Third try with parameters:
$alpha
[1] 0.6180176

$delta
[1] 0.9164396

$A
[1] 0.2172349

$delay
[1] 0.1161248

[1] "neg LL: -73.918937"
[1] "Optimal parameters:" "0.297572672452083"   "0.310414592766848"   "0.0695248653247266" 
[5] "-0.0452782713414954"

Simulate new events 

```{r}
library(ggplot2)
library(foreach)
library(doParallel)

N_runs <- 6000
T_max = max(new_times_ebola)
set.seed(5)
#week_dat_2 <- week_dat_2 %>% filter(onset >0)

# Register the parallel backend
no_cores <- detectCores()
registerDoParallel(cores=no_cores)

# Running the simulation in parallel
list_events_ebola <- foreach(i = 1:N_runs, .packages = "epihawkes") %dopar% {
  events <- hawkes_simulation(events = c(0), kernel = ray_kernel, 
                              T_max = T_max,
                              parameters = as.list(out_ebola$par), mu_fn = mu_fn,
                              print_level = print_level)
  events
}

# Creating a data frame for new_times
df_new_times_ebola <- data.frame(t = new_times_ebola, N = seq(1, length(new_times_ebola)), type = "Real Data")

# Initialize a list to hold all simulated event data frames
list_df_events_ebola <- list()

for(i in 1:N_runs){
  
  events <- list_events_ebola[[i]]
  
  # Creating a data frame for events
  df_events_ebola <- data.frame(t = events, N = seq(1, length(events)), type = paste("Simulated Data ", i))
  
  # Store each data frame in the list
  list_df_events_ebola[[i]] <- df_events_ebola
}

## CUMULATIVE PLOT

# Combine all the data into one dataframe
all_simulations <- do.call(rbind, list_df_events_ebola)

# Convert Simulation column into factor to help with plotting
all_simulations$Simulation <- as.factor(all_simulations$type)

df_new_times_ebola$Simulation <- as.factor(df_new_times_ebola$type)
# Add real data to the same dataframe
all_data <- rbind(all_simulations, df_new_times_ebola)

# Create the plot
plot_ebola <- ggplot() +
  theme_bw() +
  labs(title = "Comparison of Simulated and Real Data for Ebola",
       x = "Time (days)",
       y = expression(N(t))) +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines
plot_ebola <- plot_ebola +
  geom_path(data = subset(all_data, type != "Real Data"), 
            aes(x = t, y = N, group = Simulation), 
            color = "black", alpha = 0.3, size = 0.3)

# Add the real data line
plot_ebola <- plot_ebola +
  geom_path(data = subset(all_data, type == "Real Data"), 
            aes(x = t, y = N), color = "red", size = 1)

print(plot_ebola)

ggsave("Ebola_non_cum_plot.pdf", plot = plot_ebola, dpi = 600)


## NON cumulative plot

# Initialize an empty list to hold the data frames for each simulation
list_df_non_cum_ebola <- list()
list_df_non_cum_ebola_days <- list()
# Loop over the list of simulations
for(i in 1:N_runs){
  # Convert simulation events from seconds to dates
  non_cum_ebola <- as.POSIXct(list_events_ebola[[i]] * 86400, origin = "1995-01-06")
  
  # Convert the filtered events to weeks from the origin
  non_cum_ebola1 <- floor(as.numeric(difftime(non_cum_ebola, "1995-01-06", units = "weeks")))
  tbl <- factor(non_cum_ebola1, levels = 0:27)
  all_dates <- as.Date(seq(as.Date("1995-01-06"), max(as.Date(ebola_kikwit_1995$date)), by = "day"))
  non_cum_days <- as.data.frame(table(as.Date(non_cum_ebola)))
  names(non_cum_days) <- c("date", "onset")
  non_cum_days$date <- as.Date(non_cum_days$date)
  ## Fill the missing dates with a value of 0
  data_all <- merge(data.frame(date = all_dates), non_cum_days, by = "date", all.x = TRUE)
  # Replace NA values with 0
  data_all$onset[is.na(data_all$onset)] <- 0

  # Create a data frame for the non-cumulative counts for this simulation
  non_cum_df_ebola <- data.frame(
    Week = as.numeric(names(table(tbl))), 
    Simulated_Count = as.vector(table(tbl)),
    True_count = week_dat_2$onset
  )
  non_cum_df_ebola_days <- data.frame(
    Days = all_dates,
    True_days = ebola_kikwit_1995$onset,
    Simulated_days = data_all$onset
  )
  # Add the data frame to the list
  list_df_non_cum_ebola[[i]] <- non_cum_df_ebola
  list_df_non_cum_ebola_days[[i]] <- non_cum_df_ebola_days
}

# Prepare the simulated data
for(i in 1:N_runs){
  list_df_non_cum_ebola[[i]]$type <- paste("Simulation ", i)
  list_df_non_cum_ebola_days[[i]]$type <- paste("Simulation ", i)
}

# Combine all the data into one dataframe
all_simulations_non_cum <- do.call(rbind, list_df_non_cum_ebola)

# Convert Simulation column into factor to help with plotting
all_simulations_non_cum$Simulation <- as.factor(all_simulations_non_cum$type)

# Create the plot for WEEKS
plot_non_cum_ebola <- ggplot() +
  theme_bw() +
  labs(title = "Non-Cumulative Counts of Simulated Events and True Observations of Ebola",
       x = "Time (Weeks)",
       y = expression(N(t))) +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines
plot_non_cum_ebola <- plot_non_cum_ebola +
  geom_path(data = all_simulations_non_cum, 
            aes(x = Week, y = Simulated_Count, group = Simulation), 
            color = "black", alpha = 0.1, size = 0.3)

# Add the real data line
plot_non_cum_ebola <- plot_non_cum_ebola +
  geom_path(data = list_df_non_cum_ebola[[1]], 
            aes(x = Week, y = True_count), color = "red", size = 1)

print(plot_non_cum_ebola)


### DAYS

# Create a combined data frame with all the simulation results
all_simulations_df <- do.call(rbind, list_df_non_cum_ebola_days)
all_simulations_df$Simulation <- as.factor(all_simulations_df$type)

# Create the plot for DAYS
plot_days_ebola <- ggplot() +
  theme_bw() +
  labs(title = "Non-Cumulative Counts of Simulated Events and True Observations of Ebola",
       x = "Time (Days)",
       y = "Count") +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines
plot_days_ebola <- plot_days_ebola +
  geom_line(data = all_simulations_df, aes(x = Days, y = Simulated_days, group = Simulation), color = "black", alpha = 0.1)

# Add the real data line
plot_days_ebola <- plot_days_ebola +
  geom_line(data = all_simulations_df, aes(x = Days, y = True_days), color = "red")

print(plot_days_ebola)

```


We now plot the intensities of all simulations along with the true intensity

```{r}
# Calculate intensities for all simulations and real data
list_intensities_ebola <- list()
for(i in 1:N_runs){
  events_ebola <- list_events_ebola[[i]]
  data <- compute_intensity_function(events = events_ebola, kernel = ray_kernel, 
        T_max = max(new_times_ebola), parameters = as.list(out_ebola$par), mu_fn = mu_fn, 
        N = 5000)
  mu_ts <- mu_fn(events_ebola, parameters =  as.list(out_ebola$par))
  event_intensities <- mu_ts + conditional_intensity_list(times = events_ebola +1e-10, events = events_ebola, kernel = ray_kernel, parameters = as.list(out_ebola$par))
  data_events <- data.frame(t = events_ebola, intensity = event_intensities, type = paste("Simulated Data ", i))
  list_intensities_ebola[[i]] <- data_events
}

# Calculate intensities for the real data
data_ebola_true <- compute_intensity_function(events = new_times_ebola, kernel = ray_kernel, 
        T_max = max(new_times_ebola), parameters = as.list(out_ebola$par), mu_fn = mu_fn, 
        N = 5000)
mu_ts <- mu_fn(new_times_ebola, parameters =  as.list(out_ebola$par))
event_intensities <- mu_ts + conditional_intensity_list(times = new_times_ebola +1e-10, events = new_times_ebola, kernel = ray_kernel, parameters = as.list(out_ebola$par))
df_new_times_ebola <- data.frame(t = new_times_ebola, intensity = event_intensities, type = "Real Data")

intensities_all <- do.call(rbind, list_intensities_ebola)
intensities_all$Simulation <- as.factor(intensities_all$type)
# plot the intensities
plot_ebola_int <- ggplot() +
  theme_bw() +
  labs(title = "Comparison of Simulated and Real Intensities",
       x = "Time (weeks)",
       y = expression(lambda(t))) +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines
plot_ebola_int <- plot_ebola_int +
  geom_path(data = intensities_all, 
            aes(x = t, y = intensity, group = Simulation), 
            color = "black", alpha = 0.1, size = 0.3)

# Add the real data line
plot_ebola_int <- plot_ebola_int +
  geom_path(data = data_ebola_true, 
            aes(x = t, y = intensity), color = "red", size = 1)

print(plot_ebola_int)


```

we now find parameters for simulated data to check the validity of our model.


```{r}
set.seed(187)
mu_term<- "constant"
mu_fn <- mu_constant
mu_diff_fn <- mu_diff_constant
mu_int_fn <- mu_int_constant
# Prints log level
print_level <- 1
params1 <- list(alpha = runif(1, 0, 1),
                   delta = runif(1, 0, 1),
                   A = runif(1, 0, 1),
                delay = runif(1,0,1))

# Initial parameters on the log scale
log_params1 <- as.list(log(unlist(params1)))


library(doParallel)
library(foreach)

# Register the parallel backend
no_cores <- detectCores()
registerDoParallel(cores=no_cores)

# Define your function to optimize
optimize_func <- function(i){
  out <- optim(par = log_params1, fn = my_neg_log_likelihood, gr = transformed_gradients,
                     method = "BFGS",events = list_events_ebola[[i]], 
                     kernel = ray_kernel, 
                     mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                     mu_int_fn = mu_int_fn,
                     print_level = print_level)
  # Transform the parameters back to their original scale before storing them
  out$par <- exp(out$par)
  return(out)
}

# Running the optimization in parallel
out1 <- foreach(i = 1:N_runs, .export = c("log_params1", "my_neg_log_likelihood", "transformed_gradients", "neg_log_likelihood", "ray_derivatives",
                                           "ray_kernel", "mu_fn", "mu_diff_fn", "mu_int_fn", "print_level", "list_events"), 
                .packages = "stats") %dopar% {
  optimize_func(i)
}

# Stop the parallel backend
stopImplicitCluster()


```
Create density plots to compare the true parameters with the parameters deemed optimal from our simulations.

```{r}

new_pars <- list()
for(i in 1:N_runs){
  new_pars[[i]]<- out1[[i]]$par
}
estimated_pars <- do.call("rbind", new_pars)  # Bind all estimated parameters into a matrix
estimated_pars <- as.data.frame(estimated_pars)
library(ggplot2)
library(gridExtra)
# Create an empty list to store the plots
plot_list <- list()

#Create density plots
for(i in 1:length(out$par)) {
  # Create a dataframe for plotting
  plot_df <- data.frame(Estimated_Value = unlist(estimated_pars[, i]))
  
  # Generate a density plot for each parameter
  p <- ggplot(plot_df, aes(x = Estimated_Value)) +
    geom_density(fill = "skyblue", alpha = 0.7) +
    geom_vline(aes(xintercept = out$par[[i]]), color = "red", linetype = "dashed") +
    labs(title = paste("Parameter:", names(out$par)[i]),
         x = "Estimated Value",
         y = "Density") +
    theme_minimal()  # A clean theme
  
  # Store the plot in the list
  plot_list[[i]] <- p
}

# Arrange the plots in a grid
grid_ebola<-do.call(grid.arrange, c(plot_list, ncol = length(out$par)))

pdf("myplot_ebola.pdf", width = 15, height = 8.5) 

# Clear the grid graphical device
grid::grid.newpage()

# Draw the plot on the device
grid::grid.draw(grid_ebola)

# Close the device
dev.off()

```

Create boxplots


```{r}

# Create an empty list to store the boxplots
boxplot_list <- list()

# Loop over the parameters
for(i in 1:length(out$par)) {
  # Create a dataframe for plotting
  boxplot_df <- data.frame(Estimated_Value = unlist(estimated_pars[, i]))
  
  # Generate a boxplot for each parameter
  b <- ggplot(boxplot_df, aes(x = "", y = Estimated_Value)) +
    geom_boxplot(fill = "skyblue", alpha = 0.7) +
    geom_hline(aes(yintercept = out$par[[i]]), color = "red", linetype = "dashed") +
    labs(title = paste("Parameter:", names(out$par)[i]),
         x = "",
         y = "Estimated Value") +
    theme_minimal()  # A clean theme
  
  # Store the boxplot in the list
  boxplot_list[[i]] <- b
}

# Arrange the boxplots in a grid
grid_box<-do.call(grid.arrange, c(boxplot_list, ncol = length(out$par)))

pdf("boxplot.pdf", width = 15, height = 8.5) 

# Clear the grid graphical device
grid::grid.newpage()

# Draw the plot on the device
grid::grid.draw(grid_box)

# Close the device
dev.off()

```

Find $R_c$ for simulated events

```{r}
for(i in 1:N_runs){
  estimated_pars$Rc[i] <- unlist(estimated_pars$alpha)[i]/unlist(estimated_pars$delta)[i]
}

real_Rc <- out$par[1]/out$par[2]


# Create a dataframe for the Rc values
rc_df <- data.frame(Estimated_Rc = estimated_pars$Rc)

# Plot the density
pnew <- ggplot(rc_df, aes(x = Estimated_Rc)) +
    geom_density(fill = "skyblue", alpha = 0.5) +
    geom_vline(aes(xintercept = real_Rc), color = "red", linetype = "dashed") +
    labs(title = "Comparison of Real and Estimated Rc Values",
         x = "Estimated Rc Value",
         y = "Density") +
    theme_minimal()

print(pnew)

# Boxplot
boxplot(estimated_pars$Rc, main="Estimated Rc Values", ylab="Rc", border="blue", 
        col="lightgray", notch=TRUE, varwidth=TRUE)
abline(h = real_Rc, col="red", lty=2)

```

Use goodness of fit test to see whether our model is good.
```{r}
params<-c(mu = as.numeric(out$par[3]), alpha = as.numeric(out$par[1]), beta = as.numeric(out$par[2]))
show_hawkes_GOF(list(times = new_times,params = params))
new_times1 <- list_events[[1]] + 0.01
cumulative_intensities <- sapply(new_times1, function(t) {
  integral_intensity(events = new_times1[new_times1 <= t], int_kernel = int_ray, 
                     parameters = as.list(out$par), mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                     mu_int_fn = mu_int_fn)
})

ggplot(data.frame(x = 1:length(new_times1) , y=cumulative_intensities), aes(x = x, y = y)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  xlab("i") + 
  ylab(expression(Lambda(t[i]))) + 
  ggtitle("Cumulative Intensity vs Event Index") + 
  theme_minimal()
```














Use the exponential kernel now to see how it fits the data

```{r}
set.seed(332)
mu_term<- "constant"
mu_fn <- mu_constant
mu_diff_fn <- mu_diff_constant
mu_int_fn <- mu_int_constant
# Prints log level
print_level <- 1
params3 <- list(alpha = runif(1, 0, 1),
                   delta = runif(1, 0, 1),
                   A = runif(1, 0, 1))

out3 <- optim(par = params3, fn = neg_log_likelihood, gr = exp_derivatives,
                method = "L-BFGS-B",
                events = new_times, 
                kernel = exp_kernel, 
                mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                mu_int_fn = mu_int_fn,
                print_level = print_level)
print(sprintf("neg LL: %f", out3$value))
print(paste(c("Optimal parameters:", out3$par)))
```

Parameters: alpha = 5.32779512685593, delta = 5.5459475778066, A = 5.74481325585862

```{r}
T_max = 14
plot_decay_kernel(exp_kernel, parameters = as.list(out3$par), T_max = 14)
## Find mu
ts3 = 1:max(new_times)
ys3 = mu_fn(ts3, parameters = as.list(out3$par))
df3 <- data.frame(ts3, ys3)
p3 <- ggplot(df3) + geom_line(aes(ts3, ys3)) + 
  ylab(expression(mu)) + xlab('t')
print(p3)

##Simulate data
library(ggplot2)
library(foreach)
library(doParallel)

N_runs <- 50
T_max = 14
set.seed(5)

# Register the parallel backend
no_cores <- detectCores()
registerDoParallel(cores=no_cores)

# Running the simulation in parallel
list_events2 <- foreach(i = 1:N_runs, .packages = "epihawkes") %dopar% {
  events2 <- hawkes_simulation(events = c(0), kernel = exp_kernel, 
                              T_max = 14,
                              parameters = as.list(out3$par), mu_fn = mu_fn,
                              print_level = print_level)
  events2
}

# Creating a data frame for new_times
df_new_times <- data.frame(t = new_times, N = seq(1, length(new_times)), type = "Real Data")

# Initialize a list to hold all simulated event data frames
list_df_events2 <- list()

for(i in 1:N_runs){
  
  events2 <- list_events2[[i]]
  
  # Creating a data frame for events
  df_events2 <- data.frame(t = events2, N = seq(1, length(events2)), type = paste("Simulated Data ", i))
  
  # Store each data frame in the list
  list_df_events2[[i]] <- df_events2
}

plot2 <- ggplot() +
  theme_bw() +
  labs(title = "Comparison of Simulated and Real Data",
       x = "Time (weeks)",
       y = "Count") +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12))

# Add the simulated data lines with alpha for transparency
for(i in 1:N_runs){
  plot2 <- plot2 + geom_line(data = list_df_events2[[i]], aes(x = t, y = N), color = "black", alpha = 0.2)
}

# Add the real data line
plot2 <- plot2 + geom_line(data = df_new_times, aes(x = t, y = N), color = "red",alpha = 0.9)

# Display the plot
print(plot2)
```


The intensity for the last of the simulated data

```{r}
out3$par["delay"] = 0
data2 <- compute_intensity_function(events = events2, kernel = exp_kernel, 
        T_max = 14, parameters = as.list(out3$par), mu_fn = mu_fn, 
        N = 5000)
mu_ts2 <- mu_fn(events2, parameters =  as.list(out3$par))
event_intensities2 <- mu_ts2 + conditional_intensity_list(times = events2 +1e-10, events = events2, kernel = exp_kernel, parameters = as.list(out3$par))
data_events2 <- data.frame(t = events2, event_intensities = event_intensities2)

library(RColorBrewer)


# Find the maximum and minimum intensity
max_intensity2 <- max(data2$intensity)
min_intensity2 <- min(data2$intensity)

# Find the times associated with the maximum and minimum intensity
max_time2 <- data2$t[which.max(data2$intensity)]
min_time2 <- data2$t[which.min(data2$intensity)]

# Get a sequence of breaks for the x-axis
x_breaks2 <- seq(floor(min(data2$t)), ceiling(max(data2$t)), 1)

# Add the min/max times to the original breaks
x_breaks_new2 <- round(sort(unique(c(x_breaks2, min_time2, max_time2))))

# Use similar logic for the y-axis
y_breaks2 <- seq(floor(min(data2$intensity)), ceiling(max(data2$intensity)), 60)
#y_breaks_new <- round(sort(unique(c(y_breaks, min_intensity, max_intensity))))

# Create the plot
p4 <- ggplot(data2, aes(t, intensity)) + 
  geom_line(aes(color = "intensity")) +
  geom_point(data = data_events2, aes(t, event_intensities2)) +
  scale_color_brewer(palette = "Set1") +
  labs(x = "Time (weeks)", y = expression(lambda(t)), color = "Type", 
       title = "Intensity plot") +
  theme_minimal() +
  # Add vertical and horizontal lines at the maximum and minimum points
  geom_vline(xintercept = max_time2, linetype = "dashed", color = "red", size = 0.5) +
  geom_hline(yintercept = max_intensity2, linetype = "dashed", color = "red", size = 0.5) +
  geom_vline(xintercept = min_time2, linetype = "dashed", color = "blue", size = 0.5) +
  geom_hline(yintercept = min_intensity2, linetype = "dashed", color = "blue", size = 0.5) +
  # Add breaks and labels at these points on the x and y axes 
  scale_x_continuous(breaks = x_breaks_new2) +
  scale_y_continuous(breaks = y_breaks2)

# Print the plot
print(p4)
```
At time 0, we have that the intensity is equal to 11.07 approximately, which is the same as $\mu$ + $\alpha$. This is the case for the exponential kernel due to its form. The maximum intensity now is 240.8 at time 12.9, and the minimum intensity is 7.4 at time 0.85 weeks.

We now find the parameters for the simulated data as above with the exponential kernel now:
```{r}
set.seed(32)
mu_term<- "constant"
mu_fn <- mu_constant
mu_diff_fn <- mu_diff_constant
mu_int_fn <- mu_int_constant
# Prints log level
print_level <- 1
params4 <- list(alpha = runif(1, 0, 1),
                   delta = runif(1, 0, 1),
                   A = runif(1, 0, 1))

out4 <- optim(par = params4, fn = neg_log_likelihood, gr = exp_derivatives,
                method = "L-BFGS-B",
                events = events2, 
                kernel = exp_kernel, 
                mu_fn = mu_fn, mu_diff_fn = mu_diff_fn,
                mu_int_fn = mu_int_fn,
                print_level = print_level)
print(sprintf("neg LL: %f", out4$value))
print(paste(c("Optimal parameters:", out4$par)))
```


```{r}
new_events = c(0,0.1,0.2,0.4,0.6,0.8,1.5,2,5.6,7,9,10)
plot_intensity(new_events, T_max=10, kernel = exp_kernel,
               parameters = as.list(out3$par), mu_fn = mu_fn)
```
